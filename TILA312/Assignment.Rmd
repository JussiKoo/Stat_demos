---
title: "Assignment"
author: "Jussi Kauppinen 2891068547"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Task 1

a) 

The reason why normal distribution is so special in context of general linear models is statistical inference. Usually in case of general linear models the confidence intervals and hypothesis testing for the model parameters are important parts of the process. In cases where random variables error terms follow the normal distribution with same variance the exact distribution for the MLE of parameter vector can be determined. The MLE is actually normally distributed. This makes statistical inference simple. In cases where variances are not constant similar results arise. In cases where error terms are not normally distributed the sampling distributions can be obtained with asymptotic distributions. For large samples the standardized estimator can be approximated by normal distribution.

b) Probability density function of the $\chi^2$-distribution is

\begin{equation}
\begin{split}
f(y, k) &= \frac{1}{2^{k/2} \Gamma(k/2)} y^{k/2 - 1} e^{-y/2}\\
&= \text{exp} \left( \log \left( \frac{1}{2^{k/2} \Gamma(k/2)} y^{k/2 - 1} e^{-y/2} \right) \right)\\
&= \text{exp} \left( - \frac{k}{2} \log 2 - \log \Gamma(\frac{k}{2}) + (\frac{k}{2} - 1) \log y - \frac{y}{2} \right)\\
&= \text{exp} \left( (\frac{k}{2} - 1) \log y - (\frac{k}{2} \log 2 + \log \Gamma(\frac{k}{2})) -\frac{y}{2} \right)\\
\end{split}
\end{equation}

Let's set $\theta = \frac{k}{2}-1$, $b(\theta) = (\theta+1) \log2 + \log \Gamma(\theta+1)$, $c(y, \phi) = -\frac{y}{2}$, $\phi = 1$ and $a(\phi)=1$. We can see that this is almost fulfills the form of exponential family. Only thing is that we have $\log y$ instead of $y$. Apparently this is sufficient and $\chi^2$-distribution is a member of exponential family. Canonical link is $\theta = \frac{k}{2}-1$. However the form of the distribution yields following results:

$$E(\log(y)) = b'(\theta)$$
$$Var(\log(y)) = a(\phi)b''(\theta)$$
I think this might be the reason why glm-function in R doesn't support $\chi^2$-distribution.


# Task 2

Hurdle model consists of two components. One component for positive counts such as Poisson model and one hurdle component models if the count is zero vs larger. The hurdle models probability density function is

\begin{equation}
f_{hurdle}(y;x,z,\beta, \gamma) = 
\begin{cases}
f_{zero}(0;x,\gamma) &, \quad \text{if} y=0\\
(1-f_{zero}(0;x,\gamma)) \frac{f_{count}(y;x,\beta)}{1-f_{count}(0;x,\beta)} &, \quad \text{if} y>0\\
\end{cases}
\end{equation}

Basically the 

Let's choose some example model from the data. It seems like mountain top removal mining affects the number of salamanders on sites. Also the amount of cover objects also seems to have an effect. It can also be seen that there's lots of zero-observations which calls for hurdle model.

```{r include=FALSE}
library(glmmTMB)
library(pscl)
library(ggplot2)
library(lattice)
library(mltest)
```

```{r}
salam <- Salamanders
attach(salam)

plot(table(count))

#Mining's effect on the observed number of salamanders
plot(count ~ mined)

#Covers effect on the observed number of salamanders
plot(count ~ cover)
```

```{r}
#Regular Poisson model
fit <- glm(count ~ mined + cover, data = salam, family="poisson")
summary(fit)

#Hurdle model
fith <- hurdle(count ~ mined + cover, data = salam,
               dist="poisson", zero.dist="binomial", link="logit")
summary(fith)
```

Let's compare maximum log-likelihoods of the models and compare what kind to estimations both models give for 

```{r}
#AIC for both models
AIC(fit, fith)

#Compare log-likelihoods
logLik(fit)
logLik(fith)

#Expected number of zero-observations from both models and the actual number.
sum(dpois(0, fitted(fit)))
sum(predict(fith, type="prob")[,1])
sum(as.numeric(salam$count==0))
```

We can see from all this criteria that hurdle model is better in this case.

For the interpretations here the hurdle component basically gives the probability to encounter lizards. The count component models the positive counts of lizards.

# Task 3

```{r}
discharge <- read.table("discharge.txt", header=TRUE, sep=";")

#Shift binary values to 0 and 1
discharge$death <- discharge$death - 1
discharge$gender <- discharge$gender - 1
discharge$inh_inj <- discharge$inh_inj - 1
discharge$flame <- discharge$flame - 1
discharge$race <- discharge$race - 1
discharge$gender <- factor(discharge$gender, levels=c(0,1), labels=c("Female", "Male"))
discharge$inh_inj <- factor(discharge$inh_inj, levels=c(0,1), labels=c("No", "Yes"))
discharge$flame <- factor(discharge$flame, levels=c(0,1), labels=c("No", "Yes"))
discharge$race <- factor(discharge$race, levels=c(0,1), labels=c("Non-white", "White"))

discharge$tbsa40 <- as.numeric(discharge$tbsa >= 40)

#Convert age and tbsa to numeric values
discharge$age <- as.numeric(gsub(",", ".", discharge$age))
discharge$tbsa <- as.numeric(gsub(",", ".", discharge$tbsa))

set.seed(8547)

#sample indexes
s <- sample(nrow(discharge), 850)

#Split discharge data into modeling data and test data
data <- discharge[s,]
test <- discharge[-s,]

#New variable where age is centered to mean age
#data$c_age <- data$age - round(mean(data$age))

#New variable where tbsa is centered to mean tbsa
#data$c_tbsa <- data$tbsa - round(mean(data$tbsa))

#breaks <- c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90)
breaks <- seq(0,90,5)

labels <- c("0-5", "5-10", "10-15", "15-20", "20-25", "25-30", "30-35", "35-40",
            "40-45", "45-50", "50-55", "55-60", "60-65", "65-70", "70-75", "75-80",
            "80-85", "85-90")

#labels <- c("0-10", "10-20", "20-30", "30-40", "40-50", "50-60", "60-70", "70-80", "80-90")

#Age-groups for visualization
data$age_group <- cut(data$age, breaks = breaks, labels = labels, right = FALSE)

#Compute ratio of deaths vs cases for each age. Ages are rounded to whole numbers.
dratioage <- aggregate(data$death, by=list(data$age_group), FUN=mean)

ggplot(data=dratioage, aes(x=Group.1, y=x))+
  geom_bar(stat="identity")+
  xlab("Age")+
  ylab("Mortality rate")+
  theme_bw()
```
Effect of age to probability of dying seems to be relatively linear. One thing to consider would be dropping observations with age over 75 since they mess up the linearity a bit and it doesn't seem to affect the rate after age raises above this limit. The instruction was to use all 850 observations for modeling so they are kept in the modeling data for this task.

```{r}
breaks <- seq(0,100, 10)

labels <- c("0-10", "10-20", "20-30", "30-40",
            "40-50", "50-60", "60-70", "70-80",
            "80-90", "90-100")

data$tbsa_group <- cut(data$tbsa, breaks = breaks, labels = labels, right = FALSE)

dratioburn <- aggregate(data$death, by=list(data$tbsa_group), FUN=mean)

ggplot(data=dratioburn, aes(x=Group.1, y=x))+
  geom_bar(stat="identity")+
  xlab("Total burn area")+
  ylab("Mortality rate")+
  theme_bw()
```

Total surface burn area has obvious effect on probability of dying. We can notice that crossing 40% doesn't seem to affect mortality rate. This is why relationship doesn't look linear so transforming this variable to binary might be necessary.

```{r}
dratioinh <- aggregate(data$death, by=list(data$inh_inj), FUN=mean)

ggplot(data=dratioinh, aes(x=as.factor(Group.1), y=x))+
  geom_bar(stat="identity")+
  xlab("Burn involved inhalation injury")+
  ylab("Mortality rate")+
  ylim(0,1)
```
Inhalation injury has major effect on mortality rate.

```{r}
dratioflame <- aggregate(data$death, by=list(data$flame), FUN=mean)

ggplot(data=dratioflame, aes(x=as.factor(Group.1), y=x))+
  geom_bar(stat="identity")+
  xlab("Flame involved in burn injury")+
  ylab("Mortality rate")+
  ylim(0,1)
```

Flame being involved in injury has some effect too. However both flame involved in injury and inhalation injury can be both correlated with the total burnt surface area.

```{r}
ggplot(data=data, aes(x=inh_inj, y=tbsa))+
  geom_boxplot()

ggplot(data=data, aes(x=flame, y=tbsa))+
  geom_boxplot()

ggplot(data=data, aes(x=inh_inj, y=flame))+
  geom_jitter()
```
Inhalation injury and flame involved burn injury seem to correlate with total burnt surface area. Inhalation injury also correlates with flame involved in burn injury. 


```{r}
dratiogender <- aggregate(data$death, by=list(data$gender), FUN=mean)

ggplot(data=dratiogender, aes(x=as.factor(Group.1), y=x))+
  geom_bar(stat="identity")+
  xlab("Gender")+
  ylab("Mortality rate")+
  ylim(0,1)

dratiorace <- aggregate(data$death, by=list(data$race), FUN=mean)

ggplot(data=dratiorace, aes(x=as.factor(Group.1), y=x))+
  geom_bar(stat="identity")+
  xlab("Race")+
  ylab("Mortality rate")+
  ylim(0,1)
```
Gender and race seem to have little to no effect to mortality rate.

Let's begin by fitting a model with all variables.

```{r}
fitall <- glm(death ~ c_age + gender + race + tbsa + inh_inj + flame, data=data,
              family="binomial")
summary(fitall)
```
Significance of gender and race is in line with what we saw earlier so they are dropped from the model. There was also correlation between some variables. That's why flame is dropped from the model and inhalation injury and tbsa can be considered to be added but not together.

```{r}

fit1 <- glm(death ~ age*tbsa40, data=data,
           family="binomial")
summary(fit1)

fit2 <- glm(death ~ age+tbsa, data=data,
           family="binomial")
summary(fit2)



fit4 <- glm(death ~ age+inh_inj, data=data,
           family="binomial")
summary(fit4)

fit5 <- glm(death ~ age, data=data,
           family="binomial")
summary(fit5)



fit3 <- glm(death ~ I(age-round(mean(data$age)))*inh_inj + I(tbsa-round(mean(data$tbsa)))*inh_inj, data=data,
           family="binomial")
summary(fit3)

test <- data.frame(death = test$death, age = test$age, tbsa = test$tbsa, inh_inj = test$inh_inj)

pred <- predict(fit3, newdata = test, se.fit=TRUE, type="response")

test <- cbind(test, preds = round(pred$fit,2))
test$error <- abs(test$death-test$preds)

ggplot(data=test, aes(error))+
  geom_histogram(binwidth=0.005)+
  xlab("Prediction error")+
  ylab("Frequency")

ggplot(data=test, aes(error))+
  geom_dotplot()+
  xlab("Prediction error")+
  ylab("Frequency")

ggplot(data=test, aes(x=preds, y=death))+
  geom_point()+
  xlab("Prediction")+
  ylab("Outcome")+
  ylim(0,1)

b <- exp(coef(fit3))
b
```
Odds for 33 year old person with





